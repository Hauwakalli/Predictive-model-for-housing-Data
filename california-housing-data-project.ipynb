{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading the data and preliminary exploration\n\nThe notebook is a full analysis of the housing prices in California dataset,the ultimate goal is to predict housing prices in different districts based on demographic information for those districts,i will use the Pandas library to load it and do preliminary analysis.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-06T21:30:28.168417Z","iopub.execute_input":"2023-07-06T21:30:28.168754Z","iopub.status.idle":"2023-07-06T21:30:28.175123Z","shell.execute_reply.started":"2023-07-06T21:30:28.168720Z","shell.execute_reply":"2023-07-06T21:30:28.174221Z"}}},{"cell_type":"markdown","source":"1.\tData Acquisition: we start by downloading the California housing data which includes of longitude, latitude, housing_median_age, total_rooms,total_bedrooms,  population, households, median_income,median_house_value,  ocean_proximity. \n2.\tData Preprocessing: Before proceeding with analysis or modeling, it is important to preprocess the data. This step involves addressing missing values and outliers present in the dataset.\n3.\tExploratory Data Analysis (EDA): Following the data preprocessing stage, it is essential to perform exploratory data analysis (EDA) to gain insights into the data's distribution, examine the relationships among different features, and how these future relate to The dependent variable is ln(median house value).\n4.\tModel Building and Training: Once the exploratory data analysis (EDA) is complete, the next step is to separate the response variable (or label), in this case, the median house value, from the predictor variables. This allows me to focus on building a regression model to predict the median house value using the available features.\n5.\tModel Evaluation: Finally, i will evaluate the performance of the model using the test set.\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T22:15:15.297244Z","iopub.execute_input":"2023-07-06T22:15:15.297626Z","iopub.status.idle":"2023-07-06T22:15:15.304512Z","shell.execute_reply.started":"2023-07-06T22:15:15.297600Z","shell.execute_reply":"2023-07-06T22:15:15.303694Z"}}},{"cell_type":"markdown","source":"# Domain Knowledge\n\nIn the context of the Carlifonia Housing dataset, it's important to understand the significance of the Housing features and the role they might play in predicting the Median house value. Let's delve deeper into these features:\n\n1. **longitude**: A measure of how far west a house is; a higher value is farther west\n2. **Latitude**: A measure of how far north a house is; a higher value is farther north\n3. **HousingMedianAge**: Median age of a house within a block; a lower number is a newer building\n4. **totalRooms**: Total number of rooms within a block\n5. **TotalBedrooms**: Total number of bedrooms within a block\n6. **population**: Total number of people residing within a block\n7. **Households**: Total number of households, a group of people residing within a home unit, for a block\n8. **MedianIncome**: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n9. **MedianHouseValue**: Median house value for households within a block (measured in US Dollars)\n10. **OceanProximity**: Location of the house w.r.t ocean/sea\n","metadata":{}},{"cell_type":"markdown","source":"# Abstract\n\nThis study presents an in-depth analysis of the California housing dataset to predict the onset of housing prices in different districts based on demographic information for those districts. Our methodology comprised of a two-step process: firstly, a meticulous Exploratory Data Analysis (EDA), and secondly, the application of a Random Forest algorithm to predict the outcome.\n\n\nThis algothism works with 4 steps which are:\nStep1.Select random samples from a the data or training set. \nStep2: This algorithm will construct a decision tree for every training data. \nStep3: Voting will take place by averaging the decision tree. \nStep4: Finally,select the most voted prediction result as the final prediction result.\n\nThe EDA revealed that the median income is the most significant factor associated with the median house value while other variables like Longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,householdes showed lesser correlation. \n\nwe proceed by Training and cross validating different models and select the most promising one amongsth (Linear Regression, Decision Tree, and Random Forest) \n\nfrom the models we trained and cross validated we were able to conclude that Random Forest regression was the reliable model\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:09.315083Z","iopub.execute_input":"2023-07-07T15:55:09.315460Z","iopub.status.idle":"2023-07-07T15:55:11.360491Z","shell.execute_reply.started":"2023-07-07T15:55:09.315429Z","shell.execute_reply":"2023-07-07T15:55:11.359204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing = pd.read_csv(\"/kaggle/input/housing/housing.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.362707Z","iopub.execute_input":"2023-07-07T15:55:11.363417Z","iopub.status.idle":"2023-07-07T15:55:11.437690Z","shell.execute_reply.started":"2023-07-07T15:55:11.363382Z","shell.execute_reply":"2023-07-07T15:55:11.436587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.439072Z","iopub.execute_input":"2023-07-07T15:55:11.440284Z","iopub.status.idle":"2023-07-07T15:55:11.528920Z","shell.execute_reply.started":"2023-07-07T15:55:11.440240Z","shell.execute_reply":"2023-07-07T15:55:11.527782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.loc[:,\"latitude\":\"total_rooms\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.531495Z","iopub.execute_input":"2023-07-07T15:55:11.532059Z","iopub.status.idle":"2023-07-07T15:55:11.558446Z","shell.execute_reply.started":"2023-07-07T15:55:11.532017Z","shell.execute_reply":"2023-07-07T15:55:11.557126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing[[\"latitude\", \"longitude\"]]","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.559989Z","iopub.execute_input":"2023-07-07T15:55:11.560499Z","iopub.status.idle":"2023-07-07T15:55:11.581789Z","shell.execute_reply.started":"2023-07-07T15:55:11.560463Z","shell.execute_reply":"2023-07-07T15:55:11.580217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.583992Z","iopub.execute_input":"2023-07-07T15:55:11.584349Z","iopub.status.idle":"2023-07-07T15:55:11.614078Z","shell.execute_reply.started":"2023-07-07T15:55:11.584319Z","shell.execute_reply":"2023-07-07T15:55:11.612665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing[\"ocean_proximity\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.615907Z","iopub.execute_input":"2023-07-07T15:55:11.616638Z","iopub.status.idle":"2023-07-07T15:55:11.637799Z","shell.execute_reply.started":"2023-07-07T15:55:11.616596Z","shell.execute_reply":"2023-07-07T15:55:11.636367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing[\"ocean_proximity\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.639135Z","iopub.execute_input":"2023-07-07T15:55:11.639672Z","iopub.status.idle":"2023-07-07T15:55:11.655550Z","shell.execute_reply.started":"2023-07-07T15:55:11.639631Z","shell.execute_reply":"2023-07-07T15:55:11.654247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.657200Z","iopub.execute_input":"2023-07-07T15:55:11.658201Z","iopub.status.idle":"2023-07-07T15:55:11.668304Z","shell.execute_reply.started":"2023-07-07T15:55:11.658157Z","shell.execute_reply":"2023-07-07T15:55:11.666950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.674128Z","iopub.execute_input":"2023-07-07T15:55:11.675204Z","iopub.status.idle":"2023-07-07T15:55:11.687331Z","shell.execute_reply.started":"2023-07-07T15:55:11.675156Z","shell.execute_reply":"2023-07-07T15:55:11.685998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.688932Z","iopub.execute_input":"2023-07-07T15:55:11.690287Z","iopub.status.idle":"2023-07-07T15:55:11.720015Z","shell.execute_reply.started":"2023-07-07T15:55:11.690230Z","shell.execute_reply":"2023-07-07T15:55:11.718845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.721792Z","iopub.execute_input":"2023-07-07T15:55:11.722498Z","iopub.status.idle":"2023-07-07T15:55:11.771357Z","shell.execute_reply.started":"2023-07-07T15:55:11.722457Z","shell.execute_reply":"2023-07-07T15:55:11.770276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.773903Z","iopub.execute_input":"2023-07-07T15:55:11.774233Z","iopub.status.idle":"2023-07-07T15:55:11.804573Z","shell.execute_reply.started":"2023-07-07T15:55:11.774206Z","shell.execute_reply":"2023-07-07T15:55:11.803346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.805903Z","iopub.execute_input":"2023-07-07T15:55:11.806234Z","iopub.status.idle":"2023-07-07T15:55:11.855358Z","shell.execute_reply.started":"2023-07-07T15:55:11.806204Z","shell.execute_reply":"2023-07-07T15:55:11.854309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualising data****\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T17:21:32.278978Z","iopub.execute_input":"2023-07-06T17:21:32.279464Z","iopub.status.idle":"2023-07-06T17:21:32.290172Z","shell.execute_reply.started":"2023-07-06T17:21:32.279433Z","shell.execute_reply":"2023-07-06T17:21:32.288154Z"}}},{"cell_type":"code","source":"plt.plot(housing[\"longitude\"], housing[\"latitude\"], \".\")","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:11.856644Z","iopub.execute_input":"2023-07-07T15:55:11.857001Z","iopub.status.idle":"2023-07-07T15:55:12.240923Z","shell.execute_reply.started":"2023-07-07T15:55:11.856973Z","shell.execute_reply":"2023-07-07T15:55:12.239689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.hist(bins=50, figsize=(20,15))","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:12.242570Z","iopub.execute_input":"2023-07-07T15:55:12.243055Z","iopub.status.idle":"2023-07-07T15:55:16.173675Z","shell.execute_reply.started":"2023-07-07T15:55:12.243020Z","shell.execute_reply":"2023-07-07T15:55:16.172760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlations\n\n","metadata":{}},{"cell_type":"code","source":"corr_matrix = housing.corr()\ncorr_matrix","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:16.175103Z","iopub.execute_input":"2023-07-07T15:55:16.176134Z","iopub.status.idle":"2023-07-07T15:55:16.209101Z","shell.execute_reply.started":"2023-07-07T15:55:16.176097Z","shell.execute_reply":"2023-07-07T15:55:16.207805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix[\"median_house_value\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:16.211054Z","iopub.execute_input":"2023-07-07T15:55:16.211509Z","iopub.status.idle":"2023-07-07T15:55:16.222349Z","shell.execute_reply.started":"2023-07-07T15:55:16.211466Z","shell.execute_reply":"2023-07-07T15:55:16.220732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(corr_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:16.223808Z","iopub.execute_input":"2023-07-07T15:55:16.224188Z","iopub.status.idle":"2023-07-07T15:55:17.066501Z","shell.execute_reply.started":"2023-07-07T15:55:16.224147Z","shell.execute_reply":"2023-07-07T15:55:17.065209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph II\ncorr = corr_matrix\ntarget_corr = corr['median_house_value'].drop('median_house_value')\n\n# Sort correlation values in descending order\ntarget_corr_sorted = corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n\n# Create a heatmap of the correlations with the target column\nsns.set(font_scale=0.8)\nsns.set_style(\"white\")\nsns.set_palette(\"PuBuGn_d\")\nsns.heatmap(target_corr_sorted.to_frame(), cmap=\"coolwarm\", annot=True, fmt='.2f')\nplt.title('Correlation with median house income')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.068065Z","iopub.execute_input":"2023-07-07T15:55:17.068459Z","iopub.status.idle":"2023-07-07T15:55:17.516864Z","shell.execute_reply.started":"2023-07-07T15:55:17.068428Z","shell.execute_reply":"2023-07-07T15:55:17.515610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.total_rooms","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.518546Z","iopub.execute_input":"2023-07-07T15:55:17.518924Z","iopub.status.idle":"2023-07-07T15:55:17.528009Z","shell.execute_reply.started":"2023-07-07T15:55:17.518893Z","shell.execute_reply":"2023-07-07T15:55:17.526634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding Columnms\nThe addition of the \"per-household\" quantities in the housing dataset serves to provide normalized or standardized measures that can offer insights into the housing characteristics on a per-household basis. These new columns can provide a more meaningful representation of the data and potentially capture patterns or relationships that may be obscured when looking at the raw values.","metadata":{"execution":{"iopub.status.busy":"2023-07-07T13:25:39.629222Z","iopub.execute_input":"2023-07-07T13:25:39.630502Z","iopub.status.idle":"2023-07-07T13:25:39.643861Z","shell.execute_reply.started":"2023-07-07T13:25:39.630461Z","shell.execute_reply":"2023-07-07T13:25:39.642138Z"}}},{"cell_type":"code","source":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\nhousing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.529839Z","iopub.execute_input":"2023-07-07T15:55:17.530169Z","iopub.status.idle":"2023-07-07T15:55:17.541678Z","shell.execute_reply.started":"2023-07-07T15:55:17.530142Z","shell.execute_reply":"2023-07-07T15:55:17.540296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.543211Z","iopub.execute_input":"2023-07-07T15:55:17.543534Z","iopub.status.idle":"2023-07-07T15:55:17.577072Z","shell.execute_reply.started":"2023-07-07T15:55:17.543507Z","shell.execute_reply":"2023-07-07T15:55:17.575979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.578586Z","iopub.execute_input":"2023-07-07T15:55:17.579285Z","iopub.status.idle":"2023-07-07T15:55:17.645335Z","shell.execute_reply.started":"2023-07-07T15:55:17.579252Z","shell.execute_reply":"2023-07-07T15:55:17.644253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph II\nimport seaborn as sns\n\ncorr_matrix = housing.corr()\ncorr_matrix\ncorr = corr_matrix\ntarget_corr = corr['median_house_value'].drop('median_house_value')\n\n# Sort correlation values in descending order\ntarget_corr_sorted = corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n\n# Create a heatmap of the correlations with the target column\nsns.set(font_scale=0.8)\nsns.set_style(\"white\")\nsns.set_palette(\"PuBuGn_d\")\nsns.heatmap(target_corr_sorted.to_frame(), cmap=\"coolwarm\", annot=True, fmt='.2f')\nplt.title('Correlation with median house income')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:17.646879Z","iopub.execute_input":"2023-07-07T15:55:17.648037Z","iopub.status.idle":"2023-07-07T15:55:18.130465Z","shell.execute_reply.started":"2023-07-07T15:55:17.647994Z","shell.execute_reply":"2023-07-07T15:55:18.129344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing the data for ML\n\nWe want to predict the median house value using the other variables. So we separate the response variable (or label) from the predictor variables\n\n**CEATING TEST DATA**\n\nI proceed by spliting the dataset into a training set and a test set by splitting Randomly so as to avoid any accidental bias.i decide to go with The test_size=0.2 inside the function indicates the percentage of the data that should be held over for testing. It's usually around 80/20 or 70/30.\n","metadata":{}},{"cell_type":"code","source":"train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.131934Z","iopub.execute_input":"2023-07-07T15:55:18.132823Z","iopub.status.idle":"2023-07-07T15:55:18.143328Z","shell.execute_reply.started":"2023-07-07T15:55:18.132778Z","shell.execute_reply":"2023-07-07T15:55:18.142038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_housing = train_set.drop(\"median_house_value\", axis=1)\nhousing_labels = train_set[\"median_house_value\"].copy()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.145846Z","iopub.execute_input":"2023-07-07T15:55:18.146563Z","iopub.status.idle":"2023-07-07T15:55:18.155574Z","shell.execute_reply.started":"2023-07-07T15:55:18.146528Z","shell.execute_reply":"2023-07-07T15:55:18.154248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_labels","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.164475Z","iopub.execute_input":"2023-07-07T15:55:18.164893Z","iopub.status.idle":"2023-07-07T15:55:18.173990Z","shell.execute_reply.started":"2023-07-07T15:55:18.164861Z","shell.execute_reply":"2023-07-07T15:55:18.172592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the purposes of this prediction, it makes sense to replace the missing values from the dataset with the median of those values in that column. This is called **imputation**. We do this using a **SimpleImputer** object. But before using it, we will drop the one non-numerical column from the dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\nhousing_num = new_housing.drop(\"ocean_proximity\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.175787Z","iopub.execute_input":"2023-07-07T15:55:18.176182Z","iopub.status.idle":"2023-07-07T15:55:18.187525Z","shell.execute_reply.started":"2023-07-07T15:55:18.176151Z","shell.execute_reply":"2023-07-07T15:55:18.186343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_num","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.189126Z","iopub.execute_input":"2023-07-07T15:55:18.189493Z","iopub.status.idle":"2023-07-07T15:55:18.227816Z","shell.execute_reply.started":"2023-07-07T15:55:18.189464Z","shell.execute_reply":"2023-07-07T15:55:18.226844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = imputer.fit_transform(housing_num)\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing_num.index)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.229315Z","iopub.execute_input":"2023-07-07T15:55:18.229638Z","iopub.status.idle":"2023-07-07T15:55:18.268721Z","shell.execute_reply.started":"2023-07-07T15:55:18.229611Z","shell.execute_reply":"2023-07-07T15:55:18.267650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_tr","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.270660Z","iopub.execute_input":"2023-07-07T15:55:18.271127Z","iopub.status.idle":"2023-07-07T15:55:18.301433Z","shell.execute_reply.started":"2023-07-07T15:55:18.271086Z","shell.execute_reply":"2023-07-07T15:55:18.300521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_tr.describe()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.302835Z","iopub.execute_input":"2023-07-07T15:55:18.304168Z","iopub.status.idle":"2023-07-07T15:55:18.368772Z","shell.execute_reply.started":"2023-07-07T15:55:18.304132Z","shell.execute_reply":"2023-07-07T15:55:18.367039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_num.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.370537Z","iopub.execute_input":"2023-07-07T15:55:18.371077Z","iopub.status.idle":"2023-07-07T15:55:18.434093Z","shell.execute_reply.started":"2023-07-07T15:55:18.371043Z","shell.execute_reply":"2023-07-07T15:55:18.432721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting a model\n\n## Linear regression\n\nwe use linear regression to predict the median house price. We have to import functionality from the SKLearn library,Fitting a linear regression model to the training data.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.435809Z","iopub.execute_input":"2023-07-07T15:55:18.437073Z","iopub.status.idle":"2023-07-07T15:55:18.443343Z","shell.execute_reply.started":"2023-07-07T15:55:18.437024Z","shell.execute_reply":"2023-07-07T15:55:18.441813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin_reg = LinearRegression()\nlin_reg.fit(housing_tr, housing_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.447316Z","iopub.execute_input":"2023-07-07T15:55:18.447690Z","iopub.status.idle":"2023-07-07T15:55:18.494580Z","shell.execute_reply.started":"2023-07-07T15:55:18.447661Z","shell.execute_reply":"2023-07-07T15:55:18.493060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\n# Add a constant term to the independent variables\nw = sm.add_constant(housing_tr)\n\n# Create an OLS (Ordinary Least Squares) model\nols_model = sm.OLS(housing_labels, w)\n\n# Fit the OLS model\nols_results = ols_model.fit()\n\n# Print the model summary\nprint(ols_results.summary())","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:18.496927Z","iopub.execute_input":"2023-07-07T15:55:18.497865Z","iopub.status.idle":"2023-07-07T15:55:20.286821Z","shell.execute_reply.started":"2023-07-07T15:55:18.497801Z","shell.execute_reply":"2023-07-07T15:55:20.285624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And that is it! The fitting is done. We then inspect the coefficients","metadata":{}},{"cell_type":"code","source":"lin_reg.coef_","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.288581Z","iopub.execute_input":"2023-07-07T15:55:20.289300Z","iopub.status.idle":"2023-07-07T15:55:20.305294Z","shell.execute_reply.started":"2023-07-07T15:55:20.289260Z","shell.execute_reply":"2023-07-07T15:55:20.303921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_tr[:5]","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.311413Z","iopub.execute_input":"2023-07-07T15:55:20.317290Z","iopub.status.idle":"2023-07-07T15:55:20.375327Z","shell.execute_reply.started":"2023-07-07T15:55:20.317216Z","shell.execute_reply":"2023-07-07T15:55:20.373909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"some_data = housing_tr[:5]\nsome_labels = housing_labels[:5]\n\nprint(\"predictions:\", lin_reg.predict(some_data))\nprint(\"data:       \", list(some_labels))","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.377451Z","iopub.execute_input":"2023-07-07T15:55:20.378028Z","iopub.status.idle":"2023-07-07T15:55:20.390459Z","shell.execute_reply.started":"2023-07-07T15:55:20.377894Z","shell.execute_reply":"2023-07-07T15:55:20.389246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then proceed to compare the predictions over all the training set to the actual values of the median house value, and compute the root mean square error as a provisional measure of the accuracy of the prediction.\n\ncalculating the mean squared error (MSE) between the actual median house values (housing_labels) and the predicted values (housing_predictions). The MSE is a measure of the average squared difference between the predicted and actual values.\n\nNotice that we are not yet looking at the test data.We are just doing some rough validation using the training set.","metadata":{}},{"cell_type":"code","source":"housing_predictions = lin_reg.predict(housing_tr)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.392025Z","iopub.execute_input":"2023-07-07T15:55:20.392889Z","iopub.status.idle":"2023-07-07T15:55:20.440809Z","shell.execute_reply.started":"2023-07-07T15:55:20.392852Z","shell.execute_reply":"2023-07-07T15:55:20.438174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision tree regression\n\nwe are trying to fit other kinds of models to our data, and see how well they predict the data. Let us see how a decision tree model fares","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.450861Z","iopub.execute_input":"2023-07-07T15:55:20.455263Z","iopub.status.idle":"2023-07-07T15:55:20.467824Z","shell.execute_reply.started":"2023-07-07T15:55:20.455183Z","shell.execute_reply":"2023-07-07T15:55:20.466069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_tr, housing_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.471766Z","iopub.execute_input":"2023-07-07T15:55:20.473439Z","iopub.status.idle":"2023-07-07T15:55:20.777901Z","shell.execute_reply.started":"2023-07-07T15:55:20.473365Z","shell.execute_reply":"2023-07-07T15:55:20.776720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_predictions = tree_reg.predict(housing_tr)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.779274Z","iopub.execute_input":"2023-07-07T15:55:20.779627Z","iopub.status.idle":"2023-07-07T15:55:20.796838Z","shell.execute_reply.started":"2023-07-07T15:55:20.779595Z","shell.execute_reply":"2023-07-07T15:55:20.795646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The error is 0! Have we found the perfect model? No, this is a sure sign that we have overfitting here. Remember, we are only comparing predictions to data within the training set - we have not used the test set yet! We will do this later. This suggests overfitting, where the model has learned the training data too well and may not generalize well to new, unseen data. To validate the model's performance, it is necessary to evaluate its performance on a separate test set, which the code mentions will be done later.","metadata":{}},{"cell_type":"markdown","source":"## Random forest regression \n\nlets try a Random Forest Regression","metadata":{}},{"cell_type":"code","source":"forest_reg = RandomForestRegressor(n_estimators=10)\nforest_reg.fit(housing_tr, housing_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:20.798325Z","iopub.execute_input":"2023-07-07T15:55:20.799099Z","iopub.status.idle":"2023-07-07T15:55:22.553844Z","shell.execute_reply.started":"2023-07-07T15:55:20.799065Z","shell.execute_reply":"2023-07-07T15:55:22.552459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"housing_predictions = forest_reg.predict(housing_tr)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:22.555417Z","iopub.execute_input":"2023-07-07T15:55:22.556216Z","iopub.status.idle":"2023-07-07T15:55:22.615936Z","shell.execute_reply.started":"2023-07-07T15:55:22.556180Z","shell.execute_reply":"2023-07-07T15:55:22.615076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation\nusing the SKLearn library to do cross-validation.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, housing_tr, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:22.617252Z","iopub.execute_input":"2023-07-07T15:55:22.617905Z","iopub.status.idle":"2023-07-07T15:55:24.969527Z","shell.execute_reply.started":"2023-07-07T15:55:22.617870Z","shell.execute_reply":"2023-07-07T15:55:24.968309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_val_scores(scores):\n    print(\"scores:\", scores)\n    print(\"mean:  \", scores.mean())\n    print(\"stddev:\", scores.std())","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:24.971066Z","iopub.execute_input":"2023-07-07T15:55:24.971388Z","iopub.status.idle":"2023-07-07T15:55:24.976150Z","shell.execute_reply.started":"2023-07-07T15:55:24.971361Z","shell.execute_reply":"2023-07-07T15:55:24.975288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_val_scores(tree_rmse_scores)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:24.977646Z","iopub.execute_input":"2023-07-07T15:55:24.978304Z","iopub.status.idle":"2023-07-07T15:55:24.991869Z","shell.execute_reply.started":"2023-07-07T15:55:24.978272Z","shell.execute_reply":"2023-07-07T15:55:24.990892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(lin_reg, housing_tr, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:24.993296Z","iopub.execute_input":"2023-07-07T15:55:24.993911Z","iopub.status.idle":"2023-07-07T15:55:25.262330Z","shell.execute_reply.started":"2023-07-07T15:55:24.993864Z","shell.execute_reply":"2023-07-07T15:55:25.260519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_val_scores(lin_rmse_scores)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:25.265585Z","iopub.execute_input":"2023-07-07T15:55:25.267130Z","iopub.status.idle":"2023-07-07T15:55:25.277734Z","shell.execute_reply.started":"2023-07-07T15:55:25.267048Z","shell.execute_reply":"2023-07-07T15:55:25.276004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(forest_reg, housing_tr, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-scores)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:25.281197Z","iopub.execute_input":"2023-07-07T15:55:25.282629Z","iopub.status.idle":"2023-07-07T15:55:40.771341Z","shell.execute_reply.started":"2023-07-07T15:55:25.282540Z","shell.execute_reply":"2023-07-07T15:55:40.770058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_val_scores(forest_rmse_scores)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:40.772951Z","iopub.execute_input":"2023-07-07T15:55:40.773715Z","iopub.status.idle":"2023-07-07T15:55:40.780594Z","shell.execute_reply.started":"2023-07-07T15:55:40.773669Z","shell.execute_reply":"2023-07-07T15:55:40.779431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case, the mean RMSE of 53498.81943012941 indicates the average prediction error of the random forest model. The standard deviation of 1726.490702709601 shows the variability in the RMSE values across the folds. Overall, the random forest model seems to perform reasonably well, with an average RMSE score in the range of 53000 and a moderate standard deviation. so we have chosen the random forest model compared to others","metadata":{}},{"cell_type":"markdown","source":"# Comparing to test data","metadata":{}},{"cell_type":"markdown","source":"Now that we have chosen a model as the best, let us see how it performs on the test set","metadata":{}},{"cell_type":"code","source":"final_model = forest_reg\n\nX_test = test_set.drop(\"median_house_value\", axis=1)\nX_test = X_test.drop(\"ocean_proximity\", axis=1)\nX_tr = imputer.fit_transform(X_test)\nX_test_tr = pd.DataFrame(X_tr, columns=X_test.columns,\n                         index=X_test.index)\n\ny_test = test_set[\"median_house_value\"].copy()\n\nfinal_predictions = final_model.predict(X_test_tr)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:40.782000Z","iopub.execute_input":"2023-07-07T15:55:40.782329Z","iopub.status.idle":"2023-07-07T15:55:40.830326Z","shell.execute_reply.started":"2023-07-07T15:55:40.782301Z","shell.execute_reply":"2023-07-07T15:55:40.829159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_rmse","metadata":{"execution":{"iopub.status.busy":"2023-07-07T15:55:40.831699Z","iopub.execute_input":"2023-07-07T15:55:40.832077Z","iopub.status.idle":"2023-07-07T15:55:40.838925Z","shell.execute_reply.started":"2023-07-07T15:55:40.832045Z","shell.execute_reply":"2023-07-07T15:55:40.837589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The root mean square error is the basically the same as the one we found through cross-validation, showing that our training data is representative.","metadata":{}}]}